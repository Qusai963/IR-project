{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70d2be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ir-project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scripts import evaluate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a95909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluate_models.ModelEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edcd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR TFIDF\n",
      "==================================================\n",
      "✅ TF-IDF evaluation should be consistent with training\n",
      "==================================================\n",
      "\n",
      "Loading model assets for dataset: antique, model: tfidf...\n",
      "Assets loaded successfully.\n",
      "MAP: 61.44%  |  MRR: 69.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 61.436623086734684, 'MRR': 69.8329274891775}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('antique', 'tfidf', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f351cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR TFIDF\n",
      "==================================================\n",
      "✅ TF-IDF evaluation should be consistent with training\n",
      "==================================================\n",
      "\n",
      "Loading model assets for dataset: quora, model: tfidf...\n",
      "Assets loaded successfully.\n",
      "Processed 2000 queries...\n",
      "Processed 4000 queries...\n",
      "Processed 6000 queries...\n",
      "Processed 8000 queries...\n",
      "MAP: 69.92%  |  MRR: 71.20%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 69.91607617000504, 'MRR': 71.19935317460316}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('quora', 'tfidf', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4486b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR BERT\n",
      "==================================================\n",
      "⚠️  IMPORTANT: BERT Evaluation Checks:\n",
      "1. Ensure BERT models were trained with the latest fixes\n",
      "2. Check that document embeddings use normalize_embeddings=True\n",
      "3. Verify query preprocessing matches training (minimal preprocessing)\n",
      "4. If using old models, retrain with updated bert_service.py\n",
      "Loading model assets for dataset: antique, model: bert...\n",
      "Assets loaded successfully.\n",
      "✅ Model assets loaded successfully\n",
      "✅ Document embeddings shape: (403666, 384)\n",
      "✅ Average L2 norm of sample embeddings: 1.0000\n",
      "✅ Embeddings appear to be properly normalized\n",
      "==================================================\n",
      "\n",
      "MAP: 74.19%  |  MRR: 83.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 74.18758553505576, 'MRR': 83.87040043290045}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('antique', 'bert', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26e09cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR BERT\n",
      "==================================================\n",
      "⚠️  IMPORTANT: BERT Evaluation Checks:\n",
      "1. Ensure BERT models were trained with the latest fixes\n",
      "2. Check that document embeddings use normalize_embeddings=True\n",
      "3. Verify query preprocessing matches training (minimal preprocessing)\n",
      "4. If using old models, retrain with updated bert_service.py\n",
      "✅ Model assets loaded successfully\n",
      "✅ Document embeddings shape: (522931, 384)\n",
      "✅ Average L2 norm of sample embeddings: 1.0000\n",
      "✅ Embeddings appear to be properly normalized\n",
      "==================================================\n",
      "\n",
      "Processed 2000 queries...\n",
      "Processed 4000 queries...\n",
      "Processed 6000 queries...\n",
      "Processed 8000 queries...\n",
      "MAP: 85.23%  |  MRR: 86.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 85.23209456884607, 'MRR': 86.74679365079363}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('quora', 'bert', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37f32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR BM25\n",
      "==================================================\n",
      "✅ BM25 evaluation should be consistent with training\n",
      "Loading model assets for dataset: antique, model: bm25...\n",
      "Assets loaded successfully.\n",
      "✅ BM25 model loaded successfully\n",
      "✅ BM25 model instance available\n",
      "==================================================\n",
      "\n",
      "MAP: 86.21%  |  MRR: 92.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 86.20717878902403, 'MRR': 92.74305555555554}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('antique', 'bm25', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34c376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR BM25\n",
      "==================================================\n",
      "✅ BM25 evaluation should be consistent with training\n",
      "Loading model assets for dataset: quora, model: bm25...\n",
      "Assets loaded successfully.\n",
      "✅ BM25 model loaded successfully\n",
      "✅ BM25 model instance available\n",
      "==================================================\n",
      "\n",
      "Processed 2000 queries...\n",
      "Processed 4000 queries...\n",
      "Processed 6000 queries...\n",
      "Processed 8000 queries...\n",
      "MAP: 72.82%  |  MRR: 74.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 72.81813368606703, 'MRR': 74.05653174603174}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('quora', 'bm25', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5037e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR HYBRID_PARALLEL\n",
      "==================================================\n",
      "==================================================\n",
      "\n",
      "MAP: 0.01%  |  MRR: 0.12%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.013297218425913429, 'MRR': 0.11972466852563411}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model('antique', 'hybrid_parallel', 2, weights=(0.1, 0.1, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION CONSISTENCY CHECK FOR HYBRID_PARALLEL\n",
      "==================================================\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator.evaluate_model('quora', 'hybrid_parallel', 2, weights=(0.1, 0.6, 0.3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
